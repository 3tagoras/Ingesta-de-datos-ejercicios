{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2619a81",
   "metadata": {},
   "source": [
    "# Descargando datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289b8871",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "Utiliza los archivos json descargados con el detalle a nivel estatal, y genera unos 3 DataFrames con información sobre personas desaparecidas dependiendo de diferentes características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c3356f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # Para manejo de archivos y directorios\n",
    "import urllib.request # Una forma estandard de descargar datos\n",
    "# import requests # Otra forma no de las librerías de uso comun\n",
    "\n",
    "import datetime # Fecha de descarga\n",
    "import pandas as pd # Solo para ver el archivo descargado\n",
    "import zipfile # Descompresión de archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acb63744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\Documents\\Areas\\MCD\\1S\\Ingeniería de Características\\ingesta de datos\\Ingesta-de-datos-ejercicios\n"
     ]
    }
   ],
   "source": [
    "# pwd\n",
    "print(os.getcwd())\n",
    "\n",
    "#  Estos son los datos que vamos a descargar y donde vamos a guardarlos\n",
    "desaparecidos_RNPDNO_url = \"http://www.datamx.io/dataset/fdd2ca20-ee70-4a31-9bdf-823f3c1307a2/resource/d352810c-a22e-4d72-bb3b-33c742c799dd/download/desaparecidos3ago.zip\"\n",
    "desaparecidos_RNPDNO_archivo = \"desaparecidosRNPDNO.zip\"\n",
    "desaparecidos_corte_nacional_url = \"http://www.datamx.io/dataset/fdd2ca20-ee70-4a31-9bdf-823f3c1307a2/resource/4865e244-cf59-4d39-b863-96ed7f45cc70/download/nacional.json\"\n",
    "desaparecidos_corte_nacional_archivo = \"desaparecidos_nacional.json\"\n",
    "subdir = \"./data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7cf044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(desaparecidos_RNPDNO_archivo):\n",
    "    if not os.path.exists(subdir):\n",
    "        os.makedirs(subdir)\n",
    "    urllib.request.urlretrieve(desaparecidos_RNPDNO_url, subdir + desaparecidos_RNPDNO_archivo)  \n",
    "    with zipfile.ZipFile(subdir + desaparecidos_RNPDNO_archivo, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(subdir)\n",
    "    \n",
    "    urllib.request.urlretrieve(desaparecidos_corte_nacional_url, subdir + desaparecidos_corte_nacional_archivo)  \n",
    "\n",
    "    with open(subdir + \"info.txt\", 'w') as f:\n",
    "        f.write(\"Archivos sobre personas desaparecidas\\n\")\n",
    "        info = \"\"\"\n",
    "        Datos de desaparecidos, corte nacional y desagregación a nivel estatal, \n",
    "        por edad, por sexo, por nacionalidad, por año de desaparición y por mes\n",
    "        de desaparición para los últimos 12 meses.\n",
    "\n",
    "        Los datos se obtuvieron del RNPDNO con fecha de 03 de agosto de 2021\n",
    "        (la base de datos no se ha actualizado últimamente) \n",
    "\n",
    "        \"\"\" \n",
    "        f.write(info + '\\n')\n",
    "        f.write(\"Descargado el \" + datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + \"\\n\")\n",
    "        f.write(\"Desde: \" + desaparecidos_RNPDNO_url + \"\\n\")\n",
    "        f.write(\"Nombre: \" + desaparecidos_RNPDNO_archivo + \"\\n\")\n",
    "        f.write(\"Agregados nacionales descargados desde: \" + desaparecidos_corte_nacional_url + \"\\n\")\n",
    "        f.write(\"Nombre: \" + desaparecidos_corte_nacional_archivo + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b962fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_Sonora = 26\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51af0da8",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "Entender la estructura del archivo xml de poetas, hacer un query de otro tema que consideren interesante y generar un DataFrame con la información más importante. No olvides de comentar tu código y explicar la estructura del archivo xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abe30d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.4.3-cp313-cp313-win_amd64.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Using cached certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.3-cp313-cp313-win_amd64.whl (107 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Installing collected packages: urllib3, idna, charset_normalizer, certifi, requests\n",
      "\n",
      "   ---------------------------------------- 0/5 [urllib3]\n",
      "   ---------------------------------------- 0/5 [urllib3]\n",
      "   ---------------------------------------- 0/5 [urllib3]\n",
      "   ---------------------------------------- 0/5 [urllib3]\n",
      "   -------- ------------------------------- 1/5 [idna]\n",
      "   ---------------- ----------------------- 2/5 [charset_normalizer]\n",
      "   ---------------- ----------------------- 2/5 [charset_normalizer]\n",
      "   ------------------------ --------------- 3/5 [certifi]\n",
      "   -------------------------------- ------- 4/5 [requests]\n",
      "   -------------------------------- ------- 4/5 [requests]\n",
      "   ---------------------------------------- 5/5 [requests]\n",
      "\n",
      "Successfully installed certifi-2025.8.3 charset_normalizer-3.4.3 idna-3.10 requests-2.32.5 urllib3-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ca7c088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# URL de la API de MediaWiki de Wikipedia en español\n",
    "API_URL = \"https://es.wikipedia.org/w/api.php\"\n",
    "\n",
    "# Cabecera para identificar nuestra aplicación (buena práctica)\n",
    "HEADERS = {\n",
    "    'User-Agent': 'WikiXMLPseudoDump/1.0 (a225230115@unison.mx)'\n",
    "}\n",
    "\n",
    "def get_page_titles(category_title):\n",
    "    \"\"\"Obtiene la lista de títulos de páginas de una categoría.\"\"\"\n",
    "    titles = []\n",
    "    cmcontinue = None \n",
    "    while True:\n",
    "        params = {\n",
    "            \"action\": \"query\",\n",
    "            \"format\": \"json\",\n",
    "            \"list\": \"categorymembers\",\n",
    "            \"cmtitle\": category_title,\n",
    "            \"cmlimit\": \"500\",  # El límite máximo por petición\n",
    "            \"cmcontinue\": cmcontinue\n",
    "        }     \n",
    "        response = requests.get(API_URL, params=params, headers=HEADERS)\n",
    "        data = response.json()\n",
    "        \n",
    "        for member in data['query']['categorymembers']:\n",
    "            titles.append(member['title'])           \n",
    "        if 'continue' in data:\n",
    "            cmcontinue = data['continue']['cmcontinue']\n",
    "        else:\n",
    "            break           \n",
    "    return titles\n",
    "\n",
    "def get_page_content_in_xml(page_titles):\n",
    "    \"\"\"Obtiene el contenido de las páginas en formato XML.\"\"\"\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"xml\",\n",
    "        \"prop\": \"revisions\",\n",
    "        \"rvprop\": \"content\",\n",
    "        \"rvslots\": \"main\",\n",
    "        \"titles\": \"|\".join(page_titles)\n",
    "    }\n",
    "    response = requests.get(API_URL, params=params, headers=HEADERS)\n",
    "    return response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b9a741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obteniendo la lista de entradas de 'Académicos e investigadores de la Universidad de Sonora'...\n",
      "Se encontraron 16 entradas.\n",
      "Procesadas entradas 1 a 50 de 16\n"
     ]
    }
   ],
   "source": [
    "categoria = \"Académicos e investigadores de la Universidad de Sonora\"\n",
    "#Otros interesantes son \"Escritores de Sonora\", \"Alumnado de la Universidad de Sonora\"\n",
    "    \n",
    "print(f\"Obteniendo la lista de entradas de '{categoria}'...\")\n",
    "titles = get_page_titles('Categoría:'+categoria)\n",
    "\n",
    "print(f\"Se encontraron {len(titles)} entradas.\")\n",
    "if not titles:\n",
    "  raise ValueError(\"No se encontraron páginas en la categoría especificada.\")\n",
    "\n",
    "batch_size = 50 # Lote de títulos para la segunda petición (máximo 50)\n",
    "all_xml_data = []\n",
    "\n",
    "for i in range(0, len(titles), batch_size):\n",
    "  batch_titles = titles[i:i + batch_size]\n",
    "  xml_content = get_page_content_in_xml(batch_titles)\n",
    "  all_xml_data.append(xml_content)\n",
    "  print(f\"Procesadas entradas {i + 1} a {i + batch_size} de {len(titles)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff7ad3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Archivo 'académicos_e_investigadores_de_la_universidad_de_sonora.xml' creado exitosamente con la información completa.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_23352\\1469790014.py:8: DeprecationWarning: Testing an element's truth value will always return True in future versions.  Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  if query_element:\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as et\n",
    "# Combinar todos los XML en un solo archivo\n",
    "root = et.Element(categoria.lower().replace(\" \", \"_\"))\n",
    "for xml_data in all_xml_data:\n",
    "  # El contenido XML de la API tiene un elemento <api> y dentro <query>, que necesitamos para el contenido\n",
    "  api_root = et.fromstring(xml_data)\n",
    "  query_element = api_root.find('query')\n",
    "  if query_element:\n",
    "    # Los elementos <page> son los que contienen la información de cada poeta\n",
    "    for page_element in query_element.findall('pages/page'):\n",
    "      root.append(page_element)\n",
    "tree = et.ElementTree(root)\n",
    "\n",
    "# Guardamos en un archivo con el mismo nombre que la categoría (con .xml)\n",
    "output_filename = categoria.lower().replace(\" \", \"_\") + \".xml\"\n",
    "with open(output_filename, \"wb\") as f:\n",
    "      # Escribe el XML completo al archivo\n",
    "        tree.write(f, encoding='utf-8', xml_declaration=True)\n",
    "        print(f\"\\nArchivo '{output_filename}' creado exitosamente con la información completa.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5fe27f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_ficha_data(text):\n",
    "    start = text.find(\"{{Ficha de \")\n",
    "    if start == -1:\n",
    "        return None\n",
    "\n",
    "    i = start + 2  # skip starting {{\n",
    "    brace_count = 2\n",
    "    while i < len(text) and brace_count > 0:\n",
    "        if text[i:i+2] == \"{{\":\n",
    "            brace_count += 2\n",
    "            i += 2\n",
    "        elif text[i:i+2] == \"}}\":\n",
    "            brace_count -= 2\n",
    "            i += 2\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    block = text[start:i]\n",
    "    \n",
    "    # Extract key-value pairs\n",
    "    fields = re.findall(r'\\| *([^=|]+)\\s*=\\s*(.*)', block)\n",
    "    return fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "10230275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Alfonso López Corral',\n",
       "  'Anna Ivette Rodríguez Navarro',\n",
       "  'Daniel Avechuco Cabrera',\n",
       "  'Elizabeth Araux Sánchez',\n",
       "  'Elizabeth Cejudo Ramos',\n",
       "  'Emma Susana Speratti Piñero',\n",
       "  'Françoise Pérus',\n",
       "  'Germán Viveros Maldonado',\n",
       "  'Judith Tanori Córdova',\n",
       "  'Martha Bracho',\n",
       "  'Martha Guzmán Partida',\n",
       "  'María Rita Plancarte Martínez',\n",
       "  'Miguel Manríquez Durán',\n",
       "  'Olivia Gutu Ocampo',\n",
       "  'Tristana Landeros',\n",
       "  'Zarina Estrada Fernández'],\n",
       " [None,\n",
       "  'COLSON, Universidad de Sonora',\n",
       "  'Universidad de Sonora',\n",
       "  None,\n",
       "  'Universidad Nacional Autónoma de México. Instituto de Investigaciones Históricas/Facultad de Filosofía y Letras',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  'Universidad de Sonora',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None],\n",
       " ['1979',\n",
       "  None,\n",
       "  '{{fecha|1985}}',\n",
       "  None,\n",
       "  '27 de junio de 1980',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  '6 de febrero de 1927',\n",
       "  None,\n",
       "  None,\n",
       "  '7 de septiembre de 1957',\n",
       "  None,\n",
       "  '1974',\n",
       "  None]]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docentes = et.parse(output_filename)\n",
    "nombres = []\n",
    "escuelas = []\n",
    "fechasNacimientos= []\n",
    "for docente in docentes.getroot():\n",
    "    #print(docente.attrib['title'])\n",
    "    data = extract_ficha_data(docente[0][0][0][0].text) #para obtener el texto del articulo de wikipedia\n",
    "    nombres.append(docente.attrib['title']) #nombre del articulo de wikipedia\n",
    "    if data:\n",
    "        #print(data)\n",
    "        escuela_no_encontrada = True\n",
    "        fecha_no_encontrada = True\n",
    "        for key, value in data:\n",
    "            if key.strip() == \"alma máter\": #para obtener dodne estudiaron\n",
    "                escuela_no_encontrada = False\n",
    "                escuelas.append(value.strip().replace(\"[[\",\"\").replace(\"]]\",\"\"))\n",
    "                #print(f\"    {key.strip()}: {value.strip().replace(\"[[\",\"\").replace(\"]]\",\"\")}\")\n",
    "            if key.strip() == \"fecha de nacimiento\":#para obtener cuando nacieron\n",
    "                fecha_no_encontrada = False\n",
    "                fechasNacimientos.append(value.strip().replace(\"[[\",\"\").replace(\"]]\",\"\"))\n",
    "        if escuela_no_encontrada:\n",
    "            escuelas.append(None)\n",
    "        if fecha_no_encontrada:\n",
    "            fechasNacimientos.append(None)\n",
    "    else:\n",
    "        escuelas.append(None) #manejar las datos faltantes\n",
    "        fechasNacimientos.append(None)\n",
    "[nombres, escuelas,fechasNacimientos]\n",
    "#[len(nombres), len(escuelas), len(fechasNacimientos)] #verificar output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7f9968e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nombre</th>\n",
       "      <th>escuela</th>\n",
       "      <th>fecha_nacimiento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alfonso López Corral</td>\n",
       "      <td>None</td>\n",
       "      <td>1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anna Ivette Rodríguez Navarro</td>\n",
       "      <td>COLSON, Universidad de Sonora</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Daniel Avechuco Cabrera</td>\n",
       "      <td>Universidad de Sonora</td>\n",
       "      <td>{{fecha|1985}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elizabeth Araux Sánchez</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elizabeth Cejudo Ramos</td>\n",
       "      <td>Universidad Nacional Autónoma de México. Insti...</td>\n",
       "      <td>27 de junio de 1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Emma Susana Speratti Piñero</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Françoise Pérus</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Germán Viveros Maldonado</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Judith Tanori Córdova</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Martha Bracho</td>\n",
       "      <td>None</td>\n",
       "      <td>6 de febrero de 1927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Martha Guzmán Partida</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>María Rita Plancarte Martínez</td>\n",
       "      <td>Universidad de Sonora</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Miguel Manríquez Durán</td>\n",
       "      <td>None</td>\n",
       "      <td>7 de septiembre de 1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Olivia Gutu Ocampo</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Tristana Landeros</td>\n",
       "      <td>None</td>\n",
       "      <td>1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Zarina Estrada Fernández</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           nombre  \\\n",
       "0            Alfonso López Corral   \n",
       "1   Anna Ivette Rodríguez Navarro   \n",
       "2         Daniel Avechuco Cabrera   \n",
       "3         Elizabeth Araux Sánchez   \n",
       "4          Elizabeth Cejudo Ramos   \n",
       "5     Emma Susana Speratti Piñero   \n",
       "6                 Françoise Pérus   \n",
       "7        Germán Viveros Maldonado   \n",
       "8           Judith Tanori Córdova   \n",
       "9                   Martha Bracho   \n",
       "10          Martha Guzmán Partida   \n",
       "11  María Rita Plancarte Martínez   \n",
       "12         Miguel Manríquez Durán   \n",
       "13             Olivia Gutu Ocampo   \n",
       "14              Tristana Landeros   \n",
       "15       Zarina Estrada Fernández   \n",
       "\n",
       "                                              escuela         fecha_nacimiento  \n",
       "0                                                None                     1979  \n",
       "1                       COLSON, Universidad de Sonora                     None  \n",
       "2                               Universidad de Sonora           {{fecha|1985}}  \n",
       "3                                                None                     None  \n",
       "4   Universidad Nacional Autónoma de México. Insti...      27 de junio de 1980  \n",
       "5                                                None                     None  \n",
       "6                                                None                     None  \n",
       "7                                                None                     None  \n",
       "8                                                None                     None  \n",
       "9                                                None     6 de febrero de 1927  \n",
       "10                                               None                     None  \n",
       "11                              Universidad de Sonora                     None  \n",
       "12                                               None  7 de septiembre de 1957  \n",
       "13                                               None                     None  \n",
       "14                                               None                     1974  \n",
       "15                                               None                     None  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "docentesUnison = pd.DataFrame(data={'nombre':nombres,\"escuela\":escuelas,\"fecha_nacimiento\":fechasNacimientos})\n",
    "docentesUnison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6675a9ce",
   "metadata": {},
   "source": [
    "# Usando la API para obtener datos sobre personas desaparecidas del RNPDNO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dafedb3",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "Probar con diferentes consultas y tratar de inferir los valores que pueden tomar (o buscarlas en la documentación de la API) las diferentes variables que pueden servir para encontrar búsquedas más específicas.\n",
    "\n",
    "Por ejemplo, ¿Como podríamos consultar las estadísticas sobre mujeres desaparecidas en el municipio de Cajeme?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b38e12",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "¿Como podemos sacar lo que pasa en todo el estado, por municipios y por colonias? Intentalo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15878fc",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "¿Se puede hacer por municipio? ¿En forma programática? ¿Para algun caso especial? Intentalo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a096d135",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "Extrae alguna información del conjunto de tados que pienses que es relevante, y explica porqué."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
